{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2dfa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import scipy.stats as stats\n",
    "\n",
    "from matplotlib import patches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "import shapely.geometry as sg\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from function import DOWN_raw\n",
    "from function import ART_preprocessing as ART_pre\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc889d",
   "metadata": {},
   "source": [
    "## ENSEMBLE SAT and DOWN\n",
    "## Export Quantiles, Weibull Param and Relative Errors for each region as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8b6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_product = 'all'\n",
    "# ensemble_product = 'NoGSMaP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f631917",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = 'SAT'\n",
    "# font = 'DOWN'\n",
    "\n",
    "QC_method = 'QCv1_Flag1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7c55687",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_min, lon_max, lat_min, lat_max, area, toll = 6.5, 19, 36.5, 48, 'ITALY', 0.002\n",
    "\n",
    "Tr = [5,  10,  20,  50, 100, 200]\n",
    "Fi = 1 - 1/np.array(Tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fec31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "veneto_dir = os.path.join('/','media','arturo','T9','Data','shapes','Europa','Italy')\n",
    "\n",
    "if os.path.exists(veneto_dir):\n",
    "    REGIONS = gpd.read_file(os.path.join(veneto_dir,'Italy_regions.geojson'))\n",
    "else:\n",
    "    raise SystemExit(f\"File not found: {veneto_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6853b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_base = os.path.join('/','media','arturo','T9','Data','Italy', 'stations', 'Italy_raingauges', 'QC_MIX')\n",
    "\n",
    "# sat_base = os.path.join('/','media','arturo','T9','Data','Italy','Satellite','5_DOWN')\n",
    "sat_base = os.path.join('/','media','arturo','T9','Data','Italy','Satellite','6_DOWN_corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff8756d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>File</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Region</th>\n",
       "      <th>Code</th>\n",
       "      <th>Name</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Or_EPSG</th>\n",
       "      <th>CRS_E</th>\n",
       "      <th>CRS_N</th>\n",
       "      <th>...</th>\n",
       "      <th>Source</th>\n",
       "      <th>TimeZon</th>\n",
       "      <th>Elevation.1</th>\n",
       "      <th>Orig_EPSG</th>\n",
       "      <th>Year_Start</th>\n",
       "      <th>Year_End</th>\n",
       "      <th>INTENSE_Resp</th>\n",
       "      <th>TimeZone</th>\n",
       "      <th>elevation_DEM</th>\n",
       "      <th>Elevation_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>IT-322_AA_6535_0060_QCv1.csv</td>\n",
       "      <td>IT-322</td>\n",
       "      <td>Alto-Adige</td>\n",
       "      <td>AA_6535</td>\n",
       "      <td>VANDOIESDISOPRA</td>\n",
       "      <td>746.0</td>\n",
       "      <td>32632.0</td>\n",
       "      <td>710057.0</td>\n",
       "      <td>5187849.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Alto-Adige</td>\n",
       "      <td>UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>745.9</td>\n",
       "      <td>746.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>IT-322_AA_5650_0060_QCv1.csv</td>\n",
       "      <td>IT-322</td>\n",
       "      <td>Alto-Adige</td>\n",
       "      <td>AA_5650</td>\n",
       "      <td>SELVADEIMOLINI</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>32632.0</td>\n",
       "      <td>718972.0</td>\n",
       "      <td>5196967.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Alto-Adige</td>\n",
       "      <td>UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>1141.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          File     ISO      Region     Code  \\\n",
       "0           0  IT-322_AA_6535_0060_QCv1.csv  IT-322  Alto-Adige  AA_6535   \n",
       "1           1  IT-322_AA_5650_0060_QCv1.csv  IT-322  Alto-Adige  AA_5650   \n",
       "\n",
       "              Name  Elevation  Or_EPSG     CRS_E      CRS_N  ...      Source  \\\n",
       "0  VANDOIESDISOPRA      746.0  32632.0  710057.0  5187849.0  ...  Alto-Adige   \n",
       "1   SELVADEIMOLINI     1141.0  32632.0  718972.0  5196967.0  ...  Alto-Adige   \n",
       "\n",
       "   TimeZon Elevation.1 Orig_EPSG Year_Start Year_End INTENSE_Resp TimeZone  \\\n",
       "0      UTC         NaN       NaN        NaN      NaN          NaN      NaN   \n",
       "1      UTC         NaN       NaN        NaN      NaN          NaN      NaN   \n",
       "\n",
       "   elevation_DEM  Elevation_update  \n",
       "0          745.9             746.0  \n",
       "1         1140.0            1141.0  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METADATA = pd.read_csv(os.path.join(obs_base, 'METADATA', 'METADATA_INTENSE_UPDATE.csv'))\n",
    "METADATA[\"Lat\"] = np.round(METADATA[\"Lat\"], 6)\n",
    "METADATA[\"Lon\"] = np.round(METADATA[\"Lon\"], 6)\n",
    "METADATA.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac0ddd9",
   "metadata": {},
   "source": [
    "## Load ISO regions and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe1dfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>ISO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alto Adige</td>\n",
       "      <td>IT-322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aosta Valley</td>\n",
       "      <td>IT-230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Region     ISO\n",
       "0    Alto Adige  IT-322\n",
       "1  Aosta Valley  IT-230"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ISO_names = pd.read_csv(os.path.join('/','media','arturo','T9','Data','Italy', 'stations', 'Italy_raingauges', 'ISO_IT_REGION_EN.csv'))\n",
    "ISO_names.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b045d",
   "metadata": {},
   "source": [
    "## Load ENSEMBLE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d712d9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load all\n"
     ]
    }
   ],
   "source": [
    "print(f'Load {ensemble_product}')\n",
    "if ensemble_product == 'all':\n",
    "    dir_in = os.path.join(sat_base,'ITALY_ENSEMBLE_1dy_2002_2023_npix_2_thr_1_acf_mar_genetic_pearson.nc')\n",
    "elif ensemble_product == 'all_meadian':\n",
    "    dir_in = os.path.join(sat_base,'ITALY_ENSEMBLE_1dy_2002_2023_npix_2_thr_1_acf_mar_genetic_pearson_median.nc')\n",
    "elif ensemble_product == 'NoGSMaP':\n",
    "    dir_in = os.path.join(sat_base,'ITALY_ENSEMBLE_1dy_2002_2023_npix_2_thr_1_acf_mar_genetic_pearson_NOGSMaP.nc')\n",
    "else:\n",
    "    print(f'ensemble_product not found')\n",
    "\n",
    "data = xr.open_dataset(dir_in)\n",
    "\n",
    "lat_sat = data.lat.values\n",
    "lon_sat = data.lon.values\n",
    "lon2d_sat, lat2d_sat = np.meshgrid(lon_sat, lat_sat)\n",
    "\n",
    "Sat_year = data.year.values\n",
    "\n",
    "if font == 'SAT':\n",
    "    Sat_NYd = data.NYs.values\n",
    "    Sat_CYd = data.CYs.values\n",
    "    Sat_WYd = data.WYs.values\n",
    "elif font == 'DOWN':\n",
    "    Sat_NYd = data.NYd.values\n",
    "    Sat_CYd = data.CYd.values\n",
    "    Sat_WYd = data.WYd.values\n",
    "else:\n",
    "    print('Font dont found')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8016ac9",
   "metadata": {},
   "source": [
    "## Choose the Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f748b239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tr: 50 years\n"
     ]
    }
   ],
   "source": [
    "Tr_index = 3\n",
    "print(f'Tr: {Tr[Tr_index]} years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "853024fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>ISO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Piedmont</td>\n",
       "      <td>IT-210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aosta Valley</td>\n",
       "      <td>IT-230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lombardy</td>\n",
       "      <td>IT-250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trentino</td>\n",
       "      <td>IT-321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alto Adige</td>\n",
       "      <td>IT-322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Region     ISO\n",
       "0      Piedmont  IT-210\n",
       "1  Aosta Valley  IT-230\n",
       "2      Lombardy  IT-250\n",
       "3      Trentino  IT-321\n",
       "4    Alto Adige  IT-322"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ISO_names[\"ISO_num\"] = ISO_names[\"ISO\"].str.split(\"-\").str[1].astype(int)\n",
    "ISO_names = ISO_names.sort_values(\"ISO_num\").drop(columns=\"ISO_num\").reset_index(drop=True)\n",
    "ISO_names.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1870c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Strange Q50 Values\n",
    "# coords_remove = [\n",
    "#     (13.180000, 43.310000),\n",
    "#     (11.202635, 42.434474),\n",
    "#     (11.548882, 42.582992),\n",
    "#     (9.53778, 45.01694)\n",
    "# ]\n",
    "\n",
    "# METADATA[\"coord\"] = list(zip(METADATA[\"Lon\"], METADATA[\"Lat\"]))\n",
    "# METADATA = METADATA[~METADATA[\"coord\"].isin(coords_remove)]\n",
    "# METADATA = METADATA.drop(columns=\"coord\")\n",
    "# METADATA = METADATA.reset_index(inplace=False)\n",
    "\n",
    "# METADATA.to_csv(os.path.join(obs_base, 'METADATA', 'METADATA_INTENSE_UPDATE.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "023d0c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Piedmont (IT-210)\n",
      "2: Aosta Valley (IT-230)\n",
      "3: Lombardy (IT-250)\n",
      "4: Trentino (IT-321)\n",
      "5: Alto Adige (IT-322)\n",
      "6: Veneto (IT-340)\n",
      "7: Friuli-Venezia Giulia (IT-360)\n",
      "8: Liguria (IT-420)\n",
      "9: Emilia-Romagna (IT-450)\n",
      "10: Tuscany (IT-520)\n",
      "11: Umbria (IT-550)\n",
      "12: Marche (IT-570)\n",
      "13: Lazio (IT-620)\n",
      "14: Abruzzo (IT-650)\n",
      "15: Molise (IT-670)\n",
      "16: Campania (IT-720)\n",
      "17: Apulia (IT-750)\n",
      "18: Basilicata (IT-770)\n",
      "19: Calabria (IT-780)\n",
      "20: Sicily (IT-820)\n",
      "21: Sardinia (IT-880)\n"
     ]
    }
   ],
   "source": [
    "diccionario_OBS_WN = {}\n",
    "diccionario_OBS_WC = {}\n",
    "diccionario_OBS_WW = {}\n",
    "\n",
    "diccionario_SAT_WN = {}\n",
    "diccionario_SAT_WC = {}\n",
    "diccionario_SAT_WW = {}\n",
    "\n",
    "diccionario_RE = {}\n",
    "diccionario_LAT = {}\n",
    "diccionario_LON = {}\n",
    "diccionario_ELEV = {}\n",
    "\n",
    "diccionario_Qobs = {}\n",
    "diccionario_Qest = {}\n",
    "\n",
    "for rr in range(len(ISO_names)):#len(ISO_names)\n",
    "    region_ISO = ISO_names.iloc[rr]['ISO']\n",
    "    region_label = ISO_names[ISO_names['ISO']==region_ISO]\n",
    "\n",
    "    print(f'{rr+1}: {region_label['Region'].values[0]} ({region_ISO})')\n",
    "\n",
    "    METADATA_clear = METADATA[METADATA['ISO']==region_ISO].reset_index(inplace=False)\n",
    "\n",
    "    SAT_WN, SAT_WC, SAT_WW = [], [], []\n",
    "    OBS_WN, OBS_WC, OBS_WW = [], [], []\n",
    "    LAT, LON, RE_50, ELEV = [], [], [], []\n",
    "    Qobs, Qest = [], []\n",
    "    for nn in range(len(METADATA_clear)):#len(METADATA_clear)\n",
    "        filename = f'{METADATA_clear['File'].values[nn]}'\n",
    "        lat_obs = METADATA_clear['Lat'][nn]\n",
    "        lon_obs = METADATA_clear['Lon'][nn]\n",
    "        elev_obs = METADATA_clear['Elevation_update'][nn]\n",
    "\n",
    "        OBS_pd = pd.read_csv(os.path.join(obs_base, 'DATA_1dy', 'statistics', QC_method, region_ISO, filename))\n",
    "        OBS_pd = OBS_pd[(OBS_pd['Year']>=2002)&(OBS_pd['Year']<=2023)].reset_index(drop=True)\n",
    "        if len(OBS_pd) == 0:\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            OBS_N = OBS_pd['N'].values\n",
    "            OBS_C = OBS_pd['C'].values\n",
    "            OBS_W = OBS_pd['W'].values\n",
    "            OBS_Y = OBS_pd['Year'].values\n",
    "\n",
    "            mask = ~np.isnan(OBS_N)\n",
    "\n",
    "            OBS_N = OBS_N[mask]\n",
    "            OBS_C = OBS_C[mask]\n",
    "            OBS_W = OBS_W[mask]\n",
    "            OBS_Y = OBS_Y[mask]\n",
    "\n",
    "            if len(OBS_Y) >= 8: # greather than 8 years\n",
    "\n",
    "                x0 = np.nanmean(OBS_C)\n",
    "                OBS_Q, flag = DOWN_raw.mev_quant_update(Fi, x0, OBS_N, OBS_C, OBS_W, thresh=1)\n",
    "                OBS_Q2 = np.where(flag, OBS_Q, np.nan)\n",
    "\n",
    "                distances = ART_pre.haversine(lat2d_sat, lon2d_sat, lat_obs, lon_obs)\n",
    "                min_index = np.unravel_index(np.argmin(distances, axis=None), distances.shape)\n",
    "                Sat_NYd_ = Sat_NYd[:,min_index[0],min_index[1]]\n",
    "                Sat_CYd_ = Sat_CYd[:,min_index[0],min_index[1]]\n",
    "                Sat_WYd_ = Sat_WYd[:,min_index[0],min_index[1]]\n",
    "\n",
    "                Sat_pd = pd.DataFrame({'Year':Sat_year, 'N':Sat_NYd_, 'C':Sat_CYd_, 'W':Sat_WYd_})\n",
    "                # Sat_pd_filtered = Sat_pd[Sat_pd['Year'].isin(OBS_pd['Year'])].reset_index()\n",
    "                Sat_pd_filtered = Sat_pd.set_index('Year').loc[OBS_pd['Year']].reset_index()\n",
    "\n",
    "                SAT_N = Sat_pd_filtered['N'].values\n",
    "                SAT_C = Sat_pd_filtered['C'].values\n",
    "                SAT_W = Sat_pd_filtered['W'].values\n",
    "                SAT_Y = Sat_pd_filtered['Year'].values\n",
    "\n",
    "                SAT_N = SAT_N[mask]\n",
    "                SAT_C = SAT_C[mask]\n",
    "                SAT_W = SAT_W[mask]\n",
    "                SAT_Y = SAT_Y[mask]\n",
    "\n",
    "                if len(OBS_Y) != len(SAT_Y):\n",
    "                    print('ERROR')\n",
    "                    sys.exit()\n",
    "                else:\n",
    "                    \n",
    "                    OBS_WN.extend(OBS_N)\n",
    "                    OBS_WC.extend(OBS_C)\n",
    "                    OBS_WW.extend(OBS_W)\n",
    "                    \n",
    "                    SAT_WN.extend(SAT_N)\n",
    "                    SAT_WC.extend(SAT_C)\n",
    "                    SAT_WW.extend(SAT_W)\n",
    "                    \n",
    "                    x0 = np.nanmean(SAT_C)\n",
    "                    SAT_Q, flag = DOWN_raw.mev_quant_update(Fi, x0, SAT_N, SAT_C, SAT_W, thresh=1)\n",
    "                    SAT_Q2 = np.where(flag, SAT_Q, np.nan)\n",
    "\n",
    "                relative_e_50 = (SAT_Q2[3] - OBS_Q2[3])/OBS_Q2[3]\n",
    "\n",
    "                LAT.append(float(lat_obs))\n",
    "                LON.append(float(lon_obs))\n",
    "                RE_50.append(float(relative_e_50))\n",
    "                ELEV.append(float(elev_obs))\n",
    "                Qobs.append(float(OBS_Q2[3]))\n",
    "                Qest.append(float(SAT_Q2[3]))\n",
    "\n",
    "            else:        \n",
    "                continue\n",
    "\n",
    "            RE_50_M = np.array(RE_50)\n",
    "            # RE_50_M = RE_50_M[(RE_50_M>-1)&(RE_50_M<1)]\n",
    "            diccionario_RE[region_ISO] = RE_50_M\n",
    "\n",
    "            LAT_M = np.array(LAT)\n",
    "            # LAT_M = LAT_M[(np.array(RE_50)>-1)&(np.array(RE_50)<1)]\n",
    "            diccionario_LAT[region_ISO] = LAT_M\n",
    "\n",
    "            LON_M = np.array(LON)\n",
    "            # LON_M = LON_M[(np.array(RE_50)>-1)&(np.array(RE_50)<1)]\n",
    "            diccionario_LON[region_ISO] = LON_M\n",
    "\n",
    "            ELEV_M = np.array(ELEV)\n",
    "            # ELEV_M = ELEV_M[(np.array(RE_50)>-1)&(np.array(RE_50)<1)]\n",
    "            diccionario_ELEV[region_ISO] = ELEV_M\n",
    "\n",
    "            Qobs_M = np.array(Qobs)\n",
    "            # Qobs_M = Qobs_M[(np.array(RE_50)>-1)&(np.array(RE_50)<1)]\n",
    "            diccionario_Qobs[region_ISO] = Qobs_M\n",
    "\n",
    "            Qest_M = np.array(Qest)\n",
    "            # Qest_M = Qest_M[(np.array(RE_50)>-1)&(np.array(RE_50)<1)]\n",
    "            diccionario_Qest[region_ISO] = Qest_M\n",
    "\n",
    "            OBS_WN_N = np.array(OBS_WN)\n",
    "            diccionario_OBS_WN[region_ISO] = OBS_WN_N\n",
    "            \n",
    "            OBS_WC_N = np.array(OBS_WC)\n",
    "            diccionario_OBS_WC[region_ISO] = OBS_WC_N\n",
    "            \n",
    "            OBS_WW_N = np.array(OBS_WW)\n",
    "            diccionario_OBS_WW[region_ISO] = OBS_WW_N\n",
    "\n",
    "            SAT_WN_N = np.array(SAT_WN)\n",
    "            diccionario_SAT_WN[region_ISO] = SAT_WN_N\n",
    "            \n",
    "            SAT_WC_N = np.array(SAT_WC)\n",
    "            diccionario_SAT_WC[region_ISO] = SAT_WC_N\n",
    "            \n",
    "            SAT_WW_N = np.array(SAT_WW)\n",
    "            diccionario_SAT_WW[region_ISO] = SAT_WW_N\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab1f6a6",
   "metadata": {},
   "source": [
    "## Extreme Quantiles Tr=50 yrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ecf7be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_Qobs = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in diccionario_Qobs.items()]))\n",
    "diccionario_Qest = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in diccionario_Qest.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7771361b",
   "metadata": {},
   "source": [
    "## Weibull Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6d2eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_OBS_WN = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in diccionario_OBS_WN.items()]))\n",
    "diccionario_OBS_WC = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in diccionario_OBS_WC.items()]))\n",
    "diccionario_OBS_WW = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in diccionario_OBS_WW.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeda8b9",
   "metadata": {},
   "source": [
    "## Relative Error and Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6f81216",
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_SAT_WN = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in diccionario_SAT_WN.items()]))\n",
    "diccionario_SAT_WC = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in diccionario_SAT_WC.items()]))\n",
    "diccionario_SAT_WW = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in diccionario_SAT_WW.items()]))\n",
    "\n",
    "diccionario_RE = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in diccionario_RE.items()]))\n",
    "diccionario_LAT = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in diccionario_LAT.items()]))\n",
    "diccionario_LON = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in diccionario_LON.items()]))\n",
    "diccionario_ELEV = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in diccionario_ELEV.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1879b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_Qobs[diccionario_Qobs>500]=np.nan\n",
    "diccionario_Qest[diccionario_Qobs>500]=np.nan\n",
    "\n",
    "diccionario_OBS_WN[diccionario_Qobs>500]=np.nan\n",
    "diccionario_OBS_WC[diccionario_Qobs>500]=np.nan\n",
    "diccionario_OBS_WW[diccionario_Qobs>500]=np.nan\n",
    "\n",
    "diccionario_SAT_WN[diccionario_Qobs>500]=np.nan\n",
    "diccionario_SAT_WC[diccionario_Qobs>500]=np.nan\n",
    "diccionario_SAT_WW[diccionario_Qobs>500]=np.nan\n",
    "\n",
    "diccionario_RE[diccionario_Qobs>500]=np.nan\n",
    "diccionario_LAT[diccionario_Qobs>500]=np.nan\n",
    "diccionario_LON[diccionario_Qobs>500]=np.nan\n",
    "diccionario_ELEV[diccionario_Qobs>500]=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711de46d",
   "metadata": {},
   "source": [
    "## Export DataFrames as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50fc6580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export as: /media/arturo/T9/Data/Italy/stations/Italy_raingauges/QC_MIX/DATA_1dy/RE_ENSEMBLE_SAT/OBS_Q50.csv\n",
      "Export as: /media/arturo/T9/Data/Italy/stations/Italy_raingauges/QC_MIX/DATA_1dy/RE_ENSEMBLE_SAT/SAT_ensemble_Q50.csv\n"
     ]
    }
   ],
   "source": [
    "dir_out = os.path.join(obs_base, 'DATA_1dy', 'RE_ENSEMBLE_SAT', f'OBS_Q50.csv')\n",
    "print(f'Export as: {dir_out}')\n",
    "diccionario_Qobs.to_csv(dir_out, header=True, index=False)\n",
    "\n",
    "dir_out = os.path.join(obs_base, 'DATA_1dy', 'RE_ENSEMBLE_SAT', f'{font}_ensemble_Q50.csv')\n",
    "print(f'Export as: {dir_out}')\n",
    "diccionario_Qest.to_csv(dir_out, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9693aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export as: /media/arturo/T9/Data/Italy/stations/Italy_raingauges/QC_MIX/DATA_1dy/RE_ENSEMBLE_SAT/OBS_Weibull_N.csv\n",
      "Export as: /media/arturo/T9/Data/Italy/stations/Italy_raingauges/QC_MIX/DATA_1dy/RE_ENSEMBLE_SAT/OBS_Weibull_C.csv\n",
      "Export as: /media/arturo/T9/Data/Italy/stations/Italy_raingauges/QC_MIX/DATA_1dy/RE_ENSEMBLE_SAT/OBS_Weibull_W.csv\n",
      "Export as: /media/arturo/T9/Data/Italy/stations/Italy_raingauges/QC_MIX/DATA_1dy/RE_ENSEMBLE_SAT/SAT_Elev.csv\n",
      "Export as: /media/arturo/T9/Data/Italy/stations/Italy_raingauges/QC_MIX/DATA_1dy/RE_ENSEMBLE_SAT/OBS_relative_error_lat.csv\n",
      "Export as: /media/arturo/T9/Data/Italy/stations/Italy_raingauges/QC_MIX/DATA_1dy/RE_ENSEMBLE_SAT/OBS_relative_error_lon.csv\n"
     ]
    }
   ],
   "source": [
    "dir_out = os.path.join(obs_base, 'DATA_1dy', 'RE_ENSEMBLE_SAT', f'OBS_Weibull_N.csv')\n",
    "print(f'Export as: {dir_out}')\n",
    "diccionario_OBS_WN.to_csv(dir_out, header=True, index=False)\n",
    "\n",
    "dir_out = os.path.join(obs_base, 'DATA_1dy', 'RE_ENSEMBLE_SAT', f'OBS_Weibull_C.csv')\n",
    "print(f'Export as: {dir_out}')\n",
    "diccionario_OBS_WC.to_csv(dir_out, header=True, index=False)\n",
    "\n",
    "dir_out = os.path.join(obs_base, 'DATA_1dy', 'RE_ENSEMBLE_SAT', f'OBS_Weibull_W.csv')\n",
    "print(f'Export as: {dir_out}')\n",
    "diccionario_OBS_WW.to_csv(dir_out, header=True, index=False)\n",
    "\n",
    "dir_out = os.path.join(obs_base, 'DATA_1dy', 'RE_ENSEMBLE_SAT', f'{font}_Elev.csv')\n",
    "print(f'Export as: {dir_out}')\n",
    "diccionario_ELEV.to_csv(dir_out, header=True, index=False)\n",
    "\n",
    "dir_out = os.path.join(obs_base, 'DATA_1dy', 'RE_ENSEMBLE_SAT', f'OBS_relative_error_lat.csv')\n",
    "print(f'Export as: {dir_out}')\n",
    "diccionario_LAT.to_csv(dir_out, header=True, index=False)\n",
    "\n",
    "dir_out = os.path.join(obs_base, 'DATA_1dy', 'RE_ENSEMBLE_SAT', f'OBS_relative_error_lon.csv')\n",
    "print(f'Export as: {dir_out}')\n",
    "diccionario_LON.to_csv(dir_out, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b2319c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export as: /media/arturo/T9/Data/Italy/stations/Italy_raingauges/QC_MIX/DATA_1dy/RE_ENSEMBLE_SAT/SAT_ensemble_Weibull_N.csv\n",
      "Export as: /media/arturo/T9/Data/Italy/stations/Italy_raingauges/QC_MIX/DATA_1dy/RE_ENSEMBLE_SAT/SAT_ensemble_Weibull_C.csv\n",
      "Export as: /media/arturo/T9/Data/Italy/stations/Italy_raingauges/QC_MIX/DATA_1dy/RE_ENSEMBLE_SAT/SAT_ensemble_Weibull_W.csv\n"
     ]
    }
   ],
   "source": [
    "dir_out = os.path.join(obs_base, 'DATA_1dy', 'RE_ENSEMBLE_SAT', f'{font}_ensemble_Weibull_N.csv')\n",
    "print(f'Export as: {dir_out}')\n",
    "diccionario_SAT_WN.to_csv(dir_out, header=True, index=False)\n",
    "\n",
    "dir_out = os.path.join(obs_base, 'DATA_1dy', 'RE_ENSEMBLE_SAT', f'{font}_ensemble_Weibull_C.csv')\n",
    "print(f'Export as: {dir_out}')\n",
    "diccionario_SAT_WC.to_csv(dir_out, header=True, index=False)\n",
    "\n",
    "dir_out = os.path.join(obs_base, 'DATA_1dy', 'RE_ENSEMBLE_SAT', f'{font}_ensemble_Weibull_W.csv')\n",
    "print(f'Export as: {dir_out}')\n",
    "diccionario_SAT_WW.to_csv(dir_out, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bcb84a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export as: /media/arturo/T9/Data/Italy/stations/Italy_raingauges/QC_MIX/DATA_1dy/RE_ENSEMBLE_SAT/SAT_ensemble_relative_error.csv\n"
     ]
    }
   ],
   "source": [
    "dir_out = os.path.join(obs_base, 'DATA_1dy', 'RE_ENSEMBLE_SAT', f'{font}_ensemble_relative_error.csv')\n",
    "print(f'Export as: {dir_out}')\n",
    "diccionario_RE.to_csv(dir_out, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d5ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b6851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AXE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
