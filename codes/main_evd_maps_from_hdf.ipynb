{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import conusfun as cfun\n",
    "import downscale as down\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import dask.array as da\n",
    "\n",
    "import cartopy\n",
    "import cartopy.feature as cf\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shpreader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir  = os.path.join('..', 'data', 'tmpa_conus_data')\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant quantities:\n",
    "# TODO: get them from conusfun\n",
    "thresh = cfun.pixelkwargs['thresh']\n",
    "maxmiss = cfun.pixelkwargs['maxmiss']\n",
    "TR = cfun.Tr\n",
    "domain = 'conus'\n",
    "outname = \"evd_conus_map_{}.hdf5\".format(domain)\n",
    "# land_sea_mask = os.path.join(cfun.tmpa_dir, 'TRMM_TMPA_LandSeaMask.2.nc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ../data/tmpa_conus_data/data_tmpa_daily.hdf5\n"
     ]
    }
   ],
   "source": [
    "# TODO: get them from conusfun\n",
    "if domain == 'conus':\n",
    "    nb = 50.0\n",
    "    sb = 22.0\n",
    "    eb = -60.0\n",
    "    wb = -130.0\n",
    "    tmpa_hdf_file = os.path.join(cfun.tmpa_dir, 'data_tmpa_daily.hdf5')\n",
    "elif domain == 'world':\n",
    "    nb = 50.0\n",
    "    sb = -50.0\n",
    "    eb = 180.0\n",
    "    wb = -180.0\n",
    "    tmpa_hdf_file = os.path.join(cfun.tmpa_dir, 'data_tmpa_world_daily.hdf5')\n",
    "else:\n",
    "    print('main_evd_maps ERROR:: must specify a valid domain!')\n",
    "\n",
    "print(f'File: {tmpa_hdf_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dates', 'lat', 'lon', 'prcp']\n"
     ]
    }
   ],
   "source": [
    "# read dask array with all daily precipitation data\n",
    "f = h5py.File(tmpa_hdf_file, \"r\")\n",
    "print(list(f.keys()))\n",
    "\n",
    "tmpalat = f['lat'][:]\n",
    "tmpalon = f['lon'][:]\n",
    "nlat = np.size(tmpalat)\n",
    "nlon = np.size(tmpalon)\n",
    "dates_int = f['dates'][:]\n",
    "# hours_int = f['hours'][:]\n",
    "dset = f['prcp']\n",
    "# print('dataset shape = {}'.format(dset.shape))\n",
    "x = da.from_array(dset, chunks=(6, 6, 300))\n",
    "# UTC time\n",
    "dates = [datetime.strptime(str(integd), '%Y%m%d') for integd in dates_int]\n",
    "xconus = xr.DataArray(x,\n",
    "        coords={'lon':tmpalon, 'lat':tmpalat, 'time':dates},\n",
    "        dims=('lon', 'lat', 'time'))\n",
    "xconus = xconus.where(xconus >= -0.001)\n",
    "### end reading prcp dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018] 1\n"
     ]
    }
   ],
   "source": [
    "years_all  = df['YEAR']\n",
    "years      = np.unique(years_all)\n",
    "nyears     = np.size(years)\n",
    "maxima     = np.zeros(nyears)\n",
    "\n",
    "print(years, nyears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# fit GEV and compute quantiles\u001b[39;00m\n\u001b[1;32m     19\u001b[0m XIemp, Fiemp, TRemp \u001b[38;5;241m=\u001b[39m down\u001b[38;5;241m.\u001b[39mtab_rain_max(df)\n\u001b[0;32m---> 21\u001b[0m csi, psi, mu \u001b[38;5;241m=\u001b[39m down\u001b[38;5;241m.\u001b[39mgev_fit_lmom(XIemp) \u001b[38;5;66;03m# origianl: csi, psi, mu = down.gev_fit_lmom(XIemp)  # fit to annual maxima\u001b[39;00m\n\u001b[1;32m     23\u001b[0m qgev[ii, jj, :] \u001b[38;5;241m=\u001b[39m down\u001b[38;5;241m.\u001b[39mgev_quant(Fi, csi, psi, mu)\n",
      "File \u001b[0;32m~/github/downpy/codes/downscale.py:1195\u001b[0m, in \u001b[0;36mgev_fit_lmom\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n):  \u001b[38;5;66;03m# skip first element\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m     jj \u001b[38;5;241m=\u001b[39m j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# real index\u001b[39;00m\n\u001b[0;32m-> 1195\u001b[0m     b1 \u001b[38;5;241m=\u001b[39m b1 \u001b[38;5;241m+\u001b[39m (jj \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m x[j]\n\u001b[1;32m   1196\u001b[0m b1 \u001b[38;5;241m=\u001b[39m b1 \u001b[38;5;241m/\u001b[39m n\n\u001b[1;32m   1197\u001b[0m b2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# for each grid cell do the following:\n",
    "ntr = np.size(TR)\n",
    "Fi = 1 - 1 / TR\n",
    "qmev = np.zeros((nlon, nlat, ntr))\n",
    "qgev = np.zeros((nlon, nlat, ntr))\n",
    "for ii, clon in enumerate(tmpalon):\n",
    "    print(ii)\n",
    "    for jj, clat in enumerate(tmpalat):\n",
    "        xpixel = xconus.sel(lat=clat, lon=clon).dropna(dim='time', how='any').load()\n",
    "        ts = xpixel.values\n",
    "        years = xpixel.time.dt.year.values\n",
    "        df = pd.DataFrame({'PRCP': ts, 'YEAR': years})\n",
    "        # df = down.remove_missing_years(df, maxmiss)[0]\n",
    "        \n",
    "        Ny, Cy, Wy = down.mev_fit(df, thresh=thresh)\n",
    "        x0 = 9.0 * np.mean(Cy)\n",
    "        qmev[ii, jj, :] = down.mev_quant(Fi, x0, Ny, Cy, Wy, thresh=thresh)[0]\n",
    "        # fit GEV and compute quantiles\n",
    "        XIemp, Fiemp, TRemp = down.tab_rain_max(df)\n",
    "        \n",
    "        csi, psi, mu = down.gev_fit_lmom(XIemp) # origianl: csi, psi, mu = down.gev_fit_lmom(XIemp)  # fit to annual maxima\n",
    "        \n",
    "        qgev[ii, jj, :] = down.gev_quant(Fi, csi, psi, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir_data  = os.path.join('..', 'output', 'pixel_stats')\n",
    "outname2 = \"tmpa_mev_global_quants.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(outdir_data, outname2), \"w\") as f:\n",
    "    f.create_dataset(\"qmev\", data = qmev, dtype='f')\n",
    "    f.create_dataset(\"qgev\", data = qgev, dtype='f')\n",
    "    # f.create_dataset(\"num_complete_years\", data = num_complete_years, dtype='int32')\n",
    "    f.create_dataset(\"Tr\", data = TR,  dtype='int32')\n",
    "    f.create_dataset(\"lat\", data = tmpalat,  dtype='f')\n",
    "    f.create_dataset(\"lon\", data =tmpalon,  dtype='f')\n",
    "    # f.create_dataset(\"nmax_miss\", data =nmax_miss,  dtype='f')\n",
    "    f.create_dataset(\"thresh\", data =thresh,  dtype='f')\n",
    "    # f.create_dataset(\"min_n_complete_years\", data =min_n_years,  dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AXE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
