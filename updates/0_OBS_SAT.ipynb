{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from matplotlib import patches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from function import ART_downscale as ART_down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to export Yearly OBS Wet days and Weibull Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBS_base = os.path.join('/','media','arturo','Arturo','Data','Italy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "veneto_dir = os.path.join('/','media','arturo','Arturo','Data','shapes','Europa','Italy')\n",
    "\n",
    "if os.path.exists(veneto_dir):\n",
    "    VENETO = gpd.read_file(os.path.join(veneto_dir,'Veneto.geojson'))\n",
    "    DEM = gpd.read_file(os.path.join(veneto_dir,'Veneto_DEM_500.geojson'))\n",
    "else:\n",
    "    raise SystemExit(f\"File not found: {veneto_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBS_base = os.path.join(OBS_base,'stations','data')\n",
    "OBS_INFO_dir = os.path.join(os.path.join(OBS_base),'Veneto','Metadata_IT-340_Veneto_1dy.csv')\n",
    "\n",
    "if os.path.exists(OBS_INFO_dir):\n",
    "    INFO_pd = pd.read_csv(OBS_INFO_dir, sep=',')\n",
    "else:\n",
    "    raise SystemExit(f\"File not found: {OBS_INFO_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of files with start and end years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, lats, lons, yys, yye, nys, elev, Ns, Cs, Ws = [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for nn in range(len(INFO_pd)):\n",
    "    RAIN_pd = pd.read_csv(os.path.join(OBS_base,'Veneto','DATA','1dy_NoFlag',f'{INFO_pd['File'].values[nn]}'),sep=',')\n",
    "    RAIN_pd['Datetime'] = pd.to_datetime(RAIN_pd['Datetime'].values)\n",
    "    ss, ee = RAIN_pd['Datetime'][0].year, RAIN_pd['Datetime'][len(RAIN_pd['Datetime'])-1].year\n",
    "    ny = (ee-ss)+1\n",
    "\n",
    "    yys_new = pd.to_datetime(RAIN_pd['Datetime'].values[0]).year\n",
    "    yye_new = pd.to_datetime(RAIN_pd['Datetime'].values[-1]).year\n",
    "\n",
    "    RAIN_xr = xr.DataArray(RAIN_pd['Prec'].values,\n",
    "                        coords={'time':RAIN_pd['Datetime'].values}, \n",
    "                        dims=('time'))\n",
    "\n",
    "    RAIN_pd = RAIN_pd.dropna()\n",
    "\n",
    "    names.append(INFO_pd['File'].values[nn])\n",
    "    lats.append(INFO_pd['Lat'].values[nn])\n",
    "    lons.append(INFO_pd['Lon'].values[nn])\n",
    "    yys.append(ss)\n",
    "    yye.append(ee)\n",
    "    nys.append(ny)\n",
    "    elev.append(INFO_pd['Height'].values[nn])\n",
    "\n",
    "wa_pd = pd.DataFrame({'File_Name':names, \n",
    "                    'Lat':lats, 'Lon':lons, \n",
    "                    'YYS':yys, 'YYE':yye, \n",
    "                    'Elv':elev,'NY':nys})\n",
    "\n",
    "nameout = os.path.join(OBS_base,'Weibull','Veneto_INFO.csv')\n",
    "wa_pd.to_csv(nameout,index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>YYS</th>\n",
       "      <th>YYE</th>\n",
       "      <th>Elv</th>\n",
       "      <th>NY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IT-340_003_BL_Ar_0005min.csv</td>\n",
       "      <td>46.499984</td>\n",
       "      <td>11.876073</td>\n",
       "      <td>1984</td>\n",
       "      <td>2023</td>\n",
       "      <td>1642</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IT-340_004_NP_Be_0005min.csv</td>\n",
       "      <td>46.133632</td>\n",
       "      <td>12.195395</td>\n",
       "      <td>1993</td>\n",
       "      <td>2006</td>\n",
       "      <td>392</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT-340_009_BL_Ca_0005min.csv</td>\n",
       "      <td>46.440438</td>\n",
       "      <td>11.990042</td>\n",
       "      <td>1985</td>\n",
       "      <td>2023</td>\n",
       "      <td>1007</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IT-340_011_BL_Ma_0005min.csv</td>\n",
       "      <td>46.428671</td>\n",
       "      <td>11.904788</td>\n",
       "      <td>1986</td>\n",
       "      <td>2023</td>\n",
       "      <td>1475</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IT-340_013_NP_Bi_0005min.csv</td>\n",
       "      <td>46.352323</td>\n",
       "      <td>11.966465</td>\n",
       "      <td>1986</td>\n",
       "      <td>2010</td>\n",
       "      <td>770</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      File_Name        Lat        Lon   YYS   YYE   Elv  NY\n",
       "0  IT-340_003_BL_Ar_0005min.csv  46.499984  11.876073  1984  2023  1642  40\n",
       "1  IT-340_004_NP_Be_0005min.csv  46.133632  12.195395  1993  2006   392  14\n",
       "2  IT-340_009_BL_Ca_0005min.csv  46.440438  11.990042  1985  2023  1007  39\n",
       "3  IT-340_011_BL_Ma_0005min.csv  46.428671  11.904788  1986  2023  1475  38\n",
       "4  IT-340_013_NP_Bi_0005min.csv  46.352323  11.966465  1986  2010   770  25"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa_pd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and Export Wet days and Weibull parameter for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n",
      "Not enough data\n"
     ]
    }
   ],
   "source": [
    "names, lats, lons = [], [], []\n",
    "for nn in range(len(wa_pd)):\n",
    "    filename = f'{wa_pd['File_Name'].values[nn]}'\n",
    "    RAIN_pd = pd.read_csv(os.path.join(OBS_base,'Veneto','DATA','1dy_NoFlag', filename), sep=',')\n",
    "    RAIN_pd['Datetime'] = pd.to_datetime(RAIN_pd['Datetime'].values)\n",
    "    ss, ee = RAIN_pd['Datetime'][0].year, RAIN_pd['Datetime'][len(RAIN_pd['Datetime'])-1].year\n",
    "    ny = (ee-ss)+1\n",
    "    years = np.arange(ss,ee+1)\n",
    "\n",
    "    if ny != len(years):\n",
    "        raise SystemExit(f\"Problems with the years\")\n",
    "\n",
    "    RAIN_xr = xr.DataArray(\n",
    "                RAIN_pd['Prec'].values,\n",
    "                coords={'time':RAIN_pd['Datetime'].values}, \n",
    "                dims=('time'))\n",
    "\n",
    "    NCW = ART_down.fit_yearly_weibull_update(RAIN_xr,1,40) # 40 maximum miss data\n",
    "    N = NCW[:,0]\n",
    "    C = NCW[:,1]\n",
    "    W = NCW[:,2]\n",
    "\n",
    "    Weibull = pd.DataFrame({\n",
    "                'Year':years,\n",
    "                'N':N,\n",
    "                'C':C,\n",
    "                'W':W\n",
    "    })\n",
    "\n",
    "    nameout = os.path.join(OBS_base,'Weibull','Veneto',filename)\n",
    "    Weibull.to_csv(nameout,index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AXE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
