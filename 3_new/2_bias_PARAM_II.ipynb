{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f35d6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "playsound is relying on another python subprocess. Please use `pip install pygobject` if you want playsound to run more efficiently.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from playsound import playsound\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from function import ART_downscale as ART_down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4410535",
   "metadata": {},
   "source": [
    "## CREATE ENSEMBLE FOR PREVIOUS BIAS CORRECTION CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a8639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction, nameout, label = 'Log-Linear-Regression', 'LLc', 'Log-Linear Regression'\n",
    "# correction, nameout, label = 'Quantile Delta Mapping', 'QDM', 'Quantile Delta Mapping'\n",
    "# correction, nameout, label = 'Cummulative Distribution', 'CDFt', 'Cummulative Distribution'\n",
    "# correction, nameout, label = 'Quantile-Quantile', 'QQc', 'Quantile Quantile Mapping'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d03f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply = 'PARAM'\n",
    "frac = 0.7\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c49f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFERENCE = 'CHIRPS' # grid reference\n",
    "SATELLITES = 'ALL' \n",
    "\n",
    "yy_s, yy_e = 2002, 2023\n",
    "years_num = yy_e - yy_s + 1\n",
    "\n",
    "npix = 2\n",
    "acf = 'mar'\n",
    "cor = 'pearson'\n",
    "\n",
    "lon_min, lon_max, lat_min, lat_max, area, toll = 6.5, 19, 36.5, 48, 'ITALY', 0.002\n",
    "Tr = [5,  10,  20,  50, 100, 200]\n",
    "\n",
    "veneto_dir = os.path.join('/','media','arturo','T9','Data','shapes','Europa','Italy')\n",
    "\n",
    "if os.path.exists(veneto_dir):\n",
    "    VENETO = gpd.read_file(os.path.join(veneto_dir,'Veneto.geojson'))\n",
    "    ITALY = gpd.read_file(os.path.join(veneto_dir,'Italy_clear.geojson'))\n",
    "else:\n",
    "    raise SystemExit(f\"File not found: {veneto_dir}\")\n",
    "\n",
    "dir_base = os.path.join('/','media','arturo','T9','Data','Italy','Satellite','6_DOWN_BCorrected',apply,nameout)\n",
    "\n",
    "# CMORPH data\n",
    "data_dir = os.path.join(dir_base, f'ITALY_DOWN_CMORPH_3h_{yy_s}_{yy_e}_npix_{npix}_thr_1_acf_{acf}_genetic_{cor}_{nameout}_{str(seed).zfill(4)}.nc')\n",
    "DATA_CM = xr.open_dataset(data_dir)\n",
    "time_year = DATA_CM.year.values\n",
    "del DATA_CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a490034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_values(ref_lat2d, ref_lon2d, target_lat2d, target_lon2d, target_data):\n",
    "    \"\"\"\n",
    "    Para cada punto en la malla de referencia, busca el valor más cercano en la malla objetivo.\n",
    "    \"\"\"\n",
    "    ny, nx = ref_lat2d.shape\n",
    "    ref_points = np.column_stack((ref_lat2d.ravel(), ref_lon2d.ravel()))\n",
    "    target_points = np.column_stack((target_lat2d.ravel(), target_lon2d.ravel()))\n",
    "    tree = cKDTree(target_points)\n",
    "    _, idx = tree.query(ref_points)\n",
    "    matched_values = target_data.ravel()[idx]\n",
    "    return matched_values.reshape(ny, nx)\n",
    "\n",
    "def Create_Ensemble(REFERENCE, PARAM, seed, SATELLITES='ALL'):\n",
    "    '''\n",
    "    Create and Ensemble Product using CHIRPS grid\n",
    "    ALL = ['CMORPH', 'ERA5', 'GSMaP', 'MSWEP', 'IMERG']\n",
    "    NOGSMaP = ['CMORPH', 'ERA5', 'MSWEP', 'IMERG']\n",
    "    '''\n",
    "\n",
    "    data_dir = os.path.join(dir_base, f'ITALY_DOWN_{REFERENCE}_1dy_{yy_s}_{yy_e}_npix_{npix}_thr_1_acf_{acf}_genetic_{cor}_{nameout}_{str(seed).zfill(4)}.nc')\n",
    "    DATA_REF = xr.open_dataset(data_dir)\n",
    "    lons_REF, lats_REF = DATA_REF.lon.values, DATA_REF.lat.values\n",
    "    lon2d_REF, lat2d_REF = np.meshgrid(lons_REF, lats_REF)\n",
    "\n",
    "    if SATELLITES == 'ALL':\n",
    "\n",
    "        data_dir = os.path.join(dir_base, f'ITALY_DOWN_CMORPH_3h_{yy_s}_{yy_e}_npix_{npix}_thr_1_acf_{acf}_genetic_{cor}_{nameout}_{str(seed).zfill(4)}.nc')\n",
    "        DATA_SAT1 = xr.open_dataset(data_dir)\n",
    "        lon2d_SAT1, lat2d_SAT1 = np.meshgrid(DATA_SAT1.lon.values, DATA_SAT1.lat.values)\n",
    "\n",
    "        data_dir = os.path.join(dir_base, f'ITALY_DOWN_ERA5_3h_{yy_s}_{yy_e}_npix_{npix}_thr_1_acf_{acf}_genetic_{cor}_{nameout}_{str(seed).zfill(4)}.nc')\n",
    "        DATA_SAT2 = xr.open_dataset(data_dir)\n",
    "        lon2d_SAT2, lat2d_SAT2 = np.meshgrid(DATA_SAT2.lon.values, DATA_SAT2.lat.values)\n",
    "\n",
    "        data_dir = os.path.join(dir_base, f'ITALY_DOWN_GSMaP_3h_{yy_s}_{yy_e}_npix_{npix}_thr_1_acf_{acf}_genetic_{cor}_{nameout}_{str(seed).zfill(4)}.nc')\n",
    "        # data_dir = os.path.join(dir_base, f'ITALY_DOWN_GSMaP_3h_{yy_s}_{yy_e}_npix_{npix}_thr_1_acf_{acf}_genetic_{cor}_NoCorrection.nc')\n",
    "        DATA_SAT3 = xr.open_dataset(data_dir)\n",
    "        lon2d_SAT3, lat2d_SAT3 = np.meshgrid(DATA_SAT3.lon.values, DATA_SAT3.lat.values)\n",
    "\n",
    "        data_dir = os.path.join(dir_base, f'ITALY_DOWN_MSWEP_3h_{yy_s}_{yy_e}_npix_{npix}_thr_1_acf_{acf}_genetic_{cor}_{nameout}_{str(seed).zfill(4)}.nc')\n",
    "        DATA_SAT4 = xr.open_dataset(data_dir)\n",
    "        lon2d_SAT4, lat2d_SAT4 = np.meshgrid(DATA_SAT4.lon.values, DATA_SAT4.lat.values)\n",
    "\n",
    "        data_dir = os.path.join(dir_base, f'ITALY_DOWN_IMERG_1dy_{yy_s}_{yy_e}_npix_{npix}_thr_1_acf_{acf}_genetic_{cor}_{nameout}_{str(seed).zfill(4)}.nc')\n",
    "        DATA_SAT5 = xr.open_dataset(data_dir)\n",
    "        lon2d_SAT5, lat2d_SAT5 = np.meshgrid(DATA_SAT5.lon.values, DATA_SAT5.lat.values)\n",
    "\n",
    "        DATA_SAT = [DATA_SAT1, DATA_SAT2, DATA_SAT3, DATA_SAT4, DATA_SAT5]\n",
    "        LATLON_SAT = [\n",
    "                    (lat2d_SAT1, lon2d_SAT1),\n",
    "                    (lat2d_SAT2, lon2d_SAT2),\n",
    "                    (lat2d_SAT3, lon2d_SAT3),\n",
    "                    (lat2d_SAT4, lon2d_SAT4),\n",
    "                    (lat2d_SAT5, lon2d_SAT5),]\n",
    "\n",
    "    else: \n",
    "        print('ERROR WITH SATELLITES GROUP')\n",
    "        return 0\n",
    "\n",
    "    # ==================================================================================================\n",
    "\n",
    "    DATA_SAT = [ds.sel(year=DATA_REF.year) for ds in DATA_SAT] \n",
    "    ntimes = DATA_REF[PARAM].shape[0] \n",
    "\n",
    "    REFE_remap = np.full((ntimes, *lat2d_REF.shape), np.nan)\n",
    "    SAT_remap = [np.full_like(REFE_remap, np.nan) for _ in range(len(DATA_SAT))]\n",
    "\n",
    "    for i in range(ntimes):\n",
    "        REFE = DATA_REF[PARAM].values[i, :, :]\n",
    "        REFE_remap[i, :, :] = REFE\n",
    "\n",
    "        for k, (DATA_k, (lat2d_k, lon2d_k)) in enumerate(zip(DATA_SAT, LATLON_SAT)):\n",
    "            SAT_k = DATA_k[PARAM].values[i, :, :]\n",
    "\n",
    "            SAT_near = get_nearest_values(lat2d_REF, lon2d_REF, lat2d_k, lon2d_k, SAT_k)\n",
    "\n",
    "            SAT_remap[k][i, :, :] = SAT_near\n",
    "\n",
    "    assert all(arr.shape == REFE_remap.shape for arr in SAT_remap)\n",
    "    stacked_all = np.stack([REFE_remap] + SAT_remap,axis=0)\n",
    "\n",
    "    # ==================================================================================================\n",
    "    # Ensemble MEAN and MEDIAN\n",
    "    Ensemble_mean   = np.nanmean(stacked_all, axis=0)\n",
    "    Ensemble_median = np.nanmedian(stacked_all, axis=0)\n",
    "\n",
    "    # Ensemble WEIGHTED\n",
    "    p = stacked_all.shape[0]\n",
    "    # 1) median reference (por tiempo o agregado) -> aquí por tiempo\n",
    "    median = np.nanmedian(stacked_all, axis=0)\n",
    "    # 2) compute mean absolute dev from median per product (avg over time)\n",
    "    mad = np.nanmean(np.abs(stacked_all - median), axis=1)  # (p, ny, nx)\n",
    "    # 3) inverse mad weights (higher weight = closer to median)\n",
    "    inv_mad = 1.0 / (mad + 1e-6)\n",
    "    w = inv_mad / np.nansum(inv_mad, axis=0)  # (p, ny, nx)\n",
    "    # 4) weighted ensemble per time\n",
    "    Ensemble_weighted = np.nansum(w[:, None, :, :] * stacked_all, axis=0)  # (nt, ny, nx)\n",
    "\n",
    "    # Ensemble TRIMEAN\n",
    "    Q25 = np.nanpercentile(stacked_all, 25, axis=0)\n",
    "    Q50 = np.nanpercentile(stacked_all, 50, axis=0)\n",
    "    Q75 = np.nanpercentile(stacked_all, 75, axis=0)\n",
    "    Ensemble_trimean = (Q25 + 2*Q50 + Q75) / 4\n",
    "    # print()\n",
    "\n",
    "    return Ensemble_mean, Ensemble_median, Ensemble_weighted, Ensemble_trimean, lons_REF, lats_REF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7417fccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 7\n"
     ]
    }
   ],
   "source": [
    "print(f'Seed: {seed}')\n",
    "NYd_mean, NYd_median, NYd_weighted, NYd_trimean, lons_REF, lats_REF = Create_Ensemble(REFERENCE, 'NYd', seed, SATELLITES)\n",
    "CYd_mean, CYd_median, CYd_weighted, CYd_trimean, _, _ = Create_Ensemble(REFERENCE, 'CYd', seed, SATELLITES)\n",
    "WYd_mean, WYd_median, WYd_weighted, WYd_trimean, _, _ = Create_Ensemble(REFERENCE, 'WYd', seed, SATELLITES)\n",
    "\n",
    "lon2d_REF, lat2d_REF = np.meshgrid(lons_REF, lats_REF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1899339",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_Mevd_mean = ART_down.pre_quantiles_array(\n",
    "                            NYd_mean, \n",
    "                            CYd_mean, \n",
    "                            WYd_mean, \n",
    "                            Tr, \n",
    "                            lats_REF, lons_REF,\n",
    "                            1)\n",
    "\n",
    "ENSEMBLE_Mevd_median = ART_down.pre_quantiles_array(\n",
    "                            NYd_median, \n",
    "                            CYd_median, \n",
    "                            WYd_median, \n",
    "                            Tr, \n",
    "                            lats_REF, lons_REF,\n",
    "                            1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1475cb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export PRE data to /media/arturo/T9/Data/Italy/Satellite/6_DOWN_BCorrected/PARAM/LLc/ITALY_ENSEMBLE_ALL_1dy_2002_2023_npix_2_thr_1_acf_mar_genetic_pearson_mean_LLc_0007.nc\n"
     ]
    }
   ],
   "source": [
    "ENSEMBLE_xr = xr.Dataset(\n",
    "    data_vars={\n",
    "        \"NYd\": ((\"year\",\"lat\",\"lon\"), NYd_mean),\n",
    "        \"CYd\": ((\"year\",\"lat\",\"lon\"), CYd_mean),\n",
    "        \"WYd\": ((\"year\",\"lat\",\"lon\"), WYd_mean),\n",
    "        \"Mev_d\": ((\"Tr\",\"lat\",\"lon\"), ENSEMBLE_Mevd_mean),\n",
    "    },\n",
    "    coords={\n",
    "        'year': time_year, \n",
    "        'Tr': Tr, \n",
    "        'lat': lats_REF, \n",
    "        'lon': lons_REF\n",
    "    },\n",
    "    attrs=dict(description=f\"ENSEMBLE-mean of the downscaled precipitation data for {yy_s}-{yy_e} period using CHIRPS grid using mean\",)\n",
    ")\n",
    "\n",
    "ENSEMBLE_xr.NYd.attrs[\"units\"] = \"# days\"\n",
    "ENSEMBLE_xr.NYd.attrs[\"long_name\"] = \"Corrected Ensemble Downscaled Number of Wet Days\"\n",
    "ENSEMBLE_xr.NYd.attrs[\"origname\"] = \"Down Wet Days\"\n",
    "\n",
    "ENSEMBLE_xr.CYd.attrs[\"units\"] = \"nondimensional\"\n",
    "ENSEMBLE_xr.CYd.attrs[\"long_name\"] = \"Corrected Ensemble Downscaled Scale Parameter\"\n",
    "ENSEMBLE_xr.CYd.attrs[\"origname\"] = \"Down Scale\"\n",
    "\n",
    "ENSEMBLE_xr.WYd.attrs[\"units\"] = \"nondimensional\"\n",
    "ENSEMBLE_xr.WYd.attrs[\"long_name\"] = \"Corrected Ensemble Downscaled Shape Parameter\"\n",
    "ENSEMBLE_xr.WYd.attrs[\"origname\"] = \"Down Shape\"\n",
    "\n",
    "ENSEMBLE_xr.Mev_d.attrs[\"units\"] = \"mm/day\"\n",
    "ENSEMBLE_xr.Mev_d.attrs[\"long_name\"] = \"Corrected Ensemble Downscaled Extreme Quantiles\"\n",
    "ENSEMBLE_xr.Mev_d.attrs[\"origname\"] = \"Down Ext-Quant\"\n",
    "\n",
    "ENSEMBLE_xr.lat.attrs[\"units\"] = \"degrees_north\"\n",
    "ENSEMBLE_xr.lat.attrs[\"long_name\"] = \"Latitude\"\n",
    "\n",
    "ENSEMBLE_xr.lon.attrs[\"units\"] = \"degrees_east\"\n",
    "ENSEMBLE_xr.lon.attrs[\"long_name\"] = \"Longitude\"\n",
    "\n",
    "PRE_out = os.path.join(os.path.join(dir_base, f'ITALY_ENSEMBLE_{SATELLITES}_1dy_{yy_s}_{yy_e}_npix_{npix}_thr_1_acf_{acf}_genetic_{cor}_mean_{nameout}_{str(seed).zfill(4)}.nc'))\n",
    "print(f'Export PRE data to {PRE_out}')\n",
    "ENSEMBLE_xr.to_netcdf(PRE_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77cb5523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export PRE data to /media/arturo/T9/Data/Italy/Satellite/6_DOWN_BCorrected/PARAM/LLc/ITALY_ENSEMBLE_ALL_1dy_2002_2023_npix_2_thr_1_acf_mar_genetic_pearson_median_LLc_0007.nc\n"
     ]
    }
   ],
   "source": [
    "ENSEMBLE_xr = xr.Dataset(\n",
    "    data_vars={\n",
    "        \"NYd\": ((\"year\",\"lat\",\"lon\"), NYd_median),\n",
    "        \"CYd\": ((\"year\",\"lat\",\"lon\"), CYd_median),\n",
    "        \"WYd\": ((\"year\",\"lat\",\"lon\"), WYd_median),\n",
    "        \"Mev_d\": ((\"Tr\",\"lat\",\"lon\"), ENSEMBLE_Mevd_median),\n",
    "    },\n",
    "    coords={\n",
    "        'year': time_year, \n",
    "        'Tr': Tr, \n",
    "        'lat': lats_REF, \n",
    "        'lon': lons_REF\n",
    "    },\n",
    "    attrs=dict(description=f\"ENSEMBLE of the downscaled precipitation data for {yy_s}-{yy_e} period using CHIRPS grid using median\",)\n",
    ")\n",
    "ENSEMBLE_xr.NYd.attrs[\"units\"] = \"# days\"\n",
    "ENSEMBLE_xr.NYd.attrs[\"long_name\"] = \"Corrected Ensemble Downscaled Number of Wet Days\"\n",
    "ENSEMBLE_xr.NYd.attrs[\"origname\"] = \"Down Wet Days\"\n",
    "\n",
    "ENSEMBLE_xr.CYd.attrs[\"units\"] = \"nondimensional\"\n",
    "ENSEMBLE_xr.CYd.attrs[\"long_name\"] = \"Corrected Ensemble Downscaled Scale Parameter\"\n",
    "ENSEMBLE_xr.CYd.attrs[\"origname\"] = \"Down Scale\"\n",
    "\n",
    "ENSEMBLE_xr.WYd.attrs[\"units\"] = \"nondimensional\"\n",
    "ENSEMBLE_xr.WYd.attrs[\"long_name\"] = \"Corrected Ensemble Downscaled Shape Parameter\"\n",
    "ENSEMBLE_xr.WYd.attrs[\"origname\"] = \"Down Shape\"\n",
    "\n",
    "ENSEMBLE_xr.Mev_d.attrs[\"units\"] = \"mm/day\"\n",
    "ENSEMBLE_xr.Mev_d.attrs[\"long_name\"] = \"Corrected Ensemble Downscaled Extreme Quantiles\"\n",
    "ENSEMBLE_xr.Mev_d.attrs[\"origname\"] = \"Down Ext-Quant\"\n",
    "\n",
    "ENSEMBLE_xr.lat.attrs[\"units\"] = \"degrees_north\"\n",
    "ENSEMBLE_xr.lat.attrs[\"long_name\"] = \"Latitude\"\n",
    "\n",
    "ENSEMBLE_xr.lon.attrs[\"units\"] = \"degrees_east\"\n",
    "ENSEMBLE_xr.lon.attrs[\"long_name\"] = \"Longitude\"\n",
    "\n",
    "PRE_out = os.path.join(os.path.join(dir_base, f'ITALY_ENSEMBLE_{SATELLITES}_1dy_{yy_s}_{yy_e}_npix_{npix}_thr_1_acf_{acf}_genetic_{cor}_median_{nameout}_{str(seed).zfill(4)}.nc'))\n",
    "print(f'Export PRE data to {PRE_out}')\n",
    "ENSEMBLE_xr.to_netcdf(PRE_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8325d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "playsound(\"../sound/HOMER_DOH.mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AXE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
